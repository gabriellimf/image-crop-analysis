{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Copyright 2021 Twitter, Inc.\n",
    "SPDX-License-Identifier: Apache-2.0\n",
    "```\n",
    "\n",
    "## Image Crop Analysis\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/twitter-research/image-crop-analysis/blob/master/notebooks/Image%20Crop%20Analysis.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install \"tensorflow==2.15.0\" \"tf-keras==2.15.*\"    \n",
    "!pip install torch torchvision torchaudio\n",
    "!pip install py-feat\n",
    "!pip install scikit-image pandas matplotlib statsmodels requests dash notebook jupyterlab\n",
    "!pip install retina-face\n",
    "!pip install \"pillow==9.5.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import logging, shlex, subprocess, sys\n",
    "from pathlib import Path\n",
    "from collections import namedtuple\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.collections import PatchCollection\n",
    "from matplotlib.patches import Rectangle\n",
    "\n",
    "# — garantir visibilidade da pasta src/ —\n",
    "import pathlib\n",
    "SRC = pathlib.Path.cwd().parents[0] / \"src\"\n",
    "if str(SRC) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC)) \n",
    "\n",
    "# — modelo RetinaFace —\n",
    "from crop_api_retina_face import RetinaFaceSaliencyModel as ImageSaliencyModel\n",
    "model = ImageSaliencyModel()\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import platform\n",
    "\n",
    "BIN_MAPS = {\"Darwin\": \"mac\", \"Linux\": \"linux\"}\n",
    "\n",
    "HOME_DIR = Path(\"../\").expanduser()\n",
    "\n",
    "try:\n",
    "    import google.colab\n",
    "    ! pip install pandas scikit-learn scikit-image statsmodels requests dash\n",
    "    ! [[ -d image-crop-analysis ]] || git clone https://github.com/twitter-research/image-crop-analysis.git\n",
    "    HOME_DIR = Path(\"./image-crop-analysis\").expanduser()\n",
    "    IN_COLAB = True\n",
    "except:\n",
    "    IN_COLAB = False\n",
    "\n",
    "sys.path.append(str(HOME_DIR / \"src\"))\n",
    "bin_dir = HOME_DIR / Path(\"./bin\")\n",
    "bin_path = bin_dir / BIN_MAPS[platform.system()] / \"candidate_crops\"\n",
    "model_path = bin_dir / \"fastgaze.vxm\"\n",
    "data_dir = HOME_DIR / Path(\"./data/\")\n",
    "data_dir.exists()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_path = next(data_dir.glob(\"./*.jpeg\"))\n",
    "img_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = mpimg.imread(img_path)\n",
    "plt.imshow(img)\n",
    "plt.gca().add_patch(\n",
    "    Rectangle((0, 0), 200, 112, linewidth=1, edgecolor=\"r\", facecolor=\"none\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(img_path.absolute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmd = f\"{str(bin_path)} {str(model_path)} '{img_path.absolute()}' show_all_points\"\n",
    "cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output = subprocess.check_output(cmd, shell=True)  # Success!\n",
    "# print(output.splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! {str(bin_path)} {str(model_path)} '{img_path.absolute()}' show_all_points | head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crop_api_retina_face import RetinaFaceSaliencyModel as ImageSaliencyModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse_output(output).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ImageSaliencyModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "img_path = data_dir / \"dummy.jpeg\"       # ou outro arquivo\n",
    "\n",
    "out = model.get_output(img_path)         # chama RetinaFace\n",
    "pprint(sorted(out[\"all_salient_points\"],\n",
    "              key=lambda p: p[2],\n",
    "              reverse=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.matplotlib.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(data_dir.glob(\"./*.jpeg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_path in data_dir.glob(\"*.jpeg\"):\n",
    "    print(img_path)\n",
    "    model.plot_img_crops(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for img_path in data_dir.glob(\"*.jpeg\"):\n",
    "    print(img_path)\n",
    "    model.plot_img_crops(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from crop_api import reservoir_sampling\n",
    "\n",
    "for img_path in reservoir_sampling(data_dir.glob(\"./*.jpeg\"), K=5):\n",
    "    model.plot_img_crops(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_img_crops(data_dir / Path(\"./dummy.jpeg\"), topK=2)\n",
    "plt.savefig(\"dummy.jpg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample crops based on saliency scores\n",
    "\n",
    "\n",
    "* First, we show the top 3 crops based sorted saliency scores (highest first)\n",
    "* Next, we show the top 3 crops sampled based on saliency scores converted into probs using the following formula:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "p_i = \\frac{exp(s_i)}{Z}\\\\\n",
    "Z = \\sum_{j=0}^{j=N} exp(s_j)\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_img_crops(data_dir / Path(\"./dummy.jpeg\"), topK=3)\n",
    "plt.savefig(\"dummy_top3.jpeg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_img_crops(data_dir / Path(\"./dummy.jpeg\"), topK=3, sample=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crop an image generated using combination of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "from image_manipulation import join_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [Image.open(x) for x in data_dir.glob(\"./*.jpeg\")]\n",
    "img = join_images(images, col_wrap=2, img_size=(128, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [\n",
    "    Image.open(data_dir / Path(\"./dummy.jpeg\")),\n",
    "    Image.open(data_dir / Path(\"./dummy2.jpeg\")),\n",
    "]\n",
    "img = join_images(images, col_wrap=2, img_size=(128, 128), padding=0)\n",
    "model.plot_img_crops_using_img(img, topK=5)\n",
    "plt.savefig(\"dummy_dummy.jpeg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [\n",
    "    Image.open(data_dir / Path(\"./dummy.jpeg\")),\n",
    "    Image.open(data_dir / Path(\"./dummy2.jpeg\")),\n",
    "]\n",
    "img = join_images(images, col_wrap=1, img_size=(128, 128), padding=100)\n",
    "model.plot_img_crops_using_img(img, topK=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img.save(\"dummy_dummy_stiched.jpeg\", \"JPEG\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = Path(\"dummy_dummy_stiched.jpeg\")\n",
    "model.plot_img_crops(img_path, topK=1)\n",
    "plt.savefig(\"dummy_dummy.jpeg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.plot_img_crops(data_dir / Path(\"./dummy.jpeg\"), topK=2, aspectRatios=[0.56])\n",
    "plt.savefig(\"dummy.jpeg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = Path(\"dummy_dummy_stiched.jpeg\")\n",
    "model.plot_img_crops(img_path, topK=1, add_saliency_line=False, col_wrap=3)\n",
    "plt.savefig(\"dummy_dummy.jpeg\", bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "mldash_entity": {
   "created_at_millis": 1620095915717,
   "hash": "2fcd96a2e80eeefd7a908fa89ef475b56bffe759",
   "inferred_pdp_safe": false,
   "is_vfs_dir": false,
   "marked_pdp_safe": false,
   "owner": "smishra",
   "shared_to_everyone": false,
   "shared_to_ldap_groups": [],
   "shared_to_ldap_users": [],
   "size": 6942268,
   "tags": [],
   "uuid": "1389409090200166402",
   "vfs_path": "/user/smishra/notebooks/ImageCrop/Image Crop Analysis.ipynb"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
